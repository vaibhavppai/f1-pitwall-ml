{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering for Final Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import fastf1 as f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds_by_year = {\n",
    "    2022 : 21,\n",
    "    2023 : 21,\n",
    "    2024 : 19,\n",
    "    2025 : 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(year, round_number):\n",
    "    lap_file = f'../data/{year}/{year}_round_{round_number}_laps.csv'\n",
    "    weather_file = f'../data/{year}/{year}_round_{round_number}_weather.csv'\n",
    "    laps = pd.read_csv(lap_file)\n",
    "    weather = pd.read_csv(weather_file)\n",
    "    return laps, weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_laps_data(laps):\n",
    "    laps = laps.sort_values(['Driver', 'Stint', 'LapNumber'])\n",
    "    stint_intervals = laps.groupby(['Driver', 'Stint']).agg(\n",
    "        StartTime=('Time', 'min'),\n",
    "        EndTime=('Time', 'max'),\n",
    "        StintLength=('LapNumber', 'count'),\n",
    "        Compound=('Compound', 'first'),\n",
    "        StartingTyreLife=('TyreLife', 'first')\n",
    "    ).reset_index()\n",
    "    stint_intervals['time_tire_stint'] = stint_intervals['EndTime'] - stint_intervals['StartTime']\n",
    "    return stint_intervals, laps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_weather(weather, stint_intervals):\n",
    "    weather_summaries = []\n",
    "    for _, stint in stint_intervals.iterrows():\n",
    "        stint_weather = weather[(weather['Time'] >= stint['StartTime']) & \n",
    "                                (weather['Time'] <= stint['EndTime'])]\n",
    "        if not stint_weather.empty:\n",
    "            summary = {\n",
    "                'Driver': stint['Driver'],\n",
    "                'Stint': stint['Stint'],\n",
    "                'Avg_AirTemp': stint_weather['AirTemp'].mean(),\n",
    "                'Max_TrackTemp': stint_weather['TrackTemp'].max(),\n",
    "                'Avg_Humidity': stint_weather['Humidity'].mean(),\n",
    "                'Max_Rainfall': stint_weather['Rainfall'].max(),\n",
    "                'Avg_WindSpeed': stint_weather['WindSpeed'].mean()\n",
    "            }\n",
    "        else:\n",
    "            summary = {\n",
    "                'Driver': stint['Driver'],\n",
    "                'Stint': stint['Stint'],\n",
    "                'Avg_AirTemp': np.nan,\n",
    "                'Max_TrackTemp': np.nan,\n",
    "                'Avg_Humidity': np.nan,\n",
    "                'Max_Rainfall': np.nan,\n",
    "                'Avg_WindSpeed': np.nan\n",
    "            }\n",
    "        weather_summaries.append(summary)\n",
    "    return pd.DataFrame(weather_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in all_data: ['Time', 'Driver', 'DriverNumber', 'LapTime', 'LapNumber', 'Stint', 'PitOutTime', 'PitInTime', 'Sector1Time', 'Sector2Time', 'Sector3Time', 'Sector1SessionTime', 'Sector2SessionTime', 'Sector3SessionTime', 'SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST', 'IsPersonalBest', 'Compound', 'TyreLife', 'FreshTyre', 'Team', 'LapStartTime', 'LapStartDate', 'TrackStatus', 'Position', 'Deleted', 'DeletedReason', 'FastF1Generated', 'IsAccurate', 'time_tire_stint', 'StintLength', 'StartingTyreLife', 'Avg_AirTemp', 'Max_TrackTemp', 'Avg_Humidity', 'Max_Rainfall', 'Avg_WindSpeed', 'Year', 'RoundNumber', 'Circuit', 'driv']\n"
     ]
    }
   ],
   "source": [
    "races = [(year, round_number) for year in rounds_by_year for round_number in range(1, rounds_by_year[year] + 1)]\n",
    "schedules = {year: f1.get_event_schedule(year) for year in rounds_by_year} #get the schedule information\n",
    "all_laps_data = []\n",
    "\n",
    "for year, round_number in races:\n",
    "    laps, weather = load_data(year, round_number)\n",
    "    if laps is not None and weather is not None:\n",
    "        stint_intervals, laps = process_laps_data(laps)  # Correct unpacking\n",
    "        weather_summary = summarize_weather(weather, stint_intervals)\n",
    "        laps = laps.merge(stint_intervals[['Driver', 'Stint', 'time_tire_stint', 'StintLength', 'StartingTyreLife']], \n",
    "                         on=['Driver', 'Stint'], how='left')\n",
    "        laps = laps.merge(weather_summary, on=['Driver', 'Stint'], how='left')\n",
    "        laps['Year'] = year\n",
    "        laps['RoundNumber'] = round_number\n",
    "        \n",
    "        schedule_year = schedules.get(year)\n",
    "        circuit_row = schedule_year[schedule_year['RoundNumber'] == round_number]\n",
    "        circuit = circuit_row['Location'].values[0]\n",
    "        laps['Circuit'] = circuit\n",
    "        all_laps_data.append(laps)\n",
    "\n",
    "all_data = pd.concat(all_laps_data, ignore_index=True)\n",
    "all_data['driv'] = all_data['Driver']\n",
    "print(\"Columns in all_data:\", all_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_data = all_data.sort_values(['Year', 'RoundNumber', 'Driver', 'Stint', 'LapNumber'])\n",
    "all_data['StintLapNumber'] = all_data.groupby(['Year', 'RoundNumber', 'Driver', 'Stint']).cumcount() + 1\n",
    "all_data['RemainingLaps'] = all_data['StintLength'] - all_data['StintLapNumber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1f/z0fw8fgj5dn80_1mwsm3ssn00000gp/T/ipykernel_5899/1640374376.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  all_data[feature] = all_data.groupby(['Year', 'RoundNumber'])[feature].transform(lambda x: x.fillna(x.mean()))\n"
     ]
    }
   ],
   "source": [
    "for feature in ['Avg_AirTemp', 'Max_TrackTemp', 'Avg_Humidity', 'Max_Rainfall', 'Avg_WindSpeed']:\n",
    "    all_data[feature] = all_data.groupby(['Year', 'RoundNumber'])[feature].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Time', 'DriverNumber', 'LapTime', 'LapNumber', 'Stint', 'PitOutTime', 'PitInTime', 'Sector1Time', 'Sector2Time', 'Sector3Time', 'Sector1SessionTime', 'Sector2SessionTime', 'Sector3SessionTime', 'SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST', 'IsPersonalBest', 'TyreLife', 'Team', 'LapStartTime', 'LapStartDate', 'TrackStatus', 'Position', 'Deleted', 'DeletedReason', 'FastF1Generated', 'IsAccurate', 'time_tire_stint', 'StintLength', 'StartingTyreLife', 'Avg_AirTemp', 'Max_TrackTemp', 'Avg_Humidity', 'Max_Rainfall', 'Avg_WindSpeed', 'Year', 'RoundNumber', 'driv', 'StintLapNumber', 'RemainingLaps', 'Compound_HARD', 'Compound_INTERMEDIATE', 'Compound_MEDIUM', 'Compound_SOFT', 'Compound_WET', 'FreshTyre_False', 'FreshTyre_True', 'Circuit_Austin', 'Circuit_Baku', 'Circuit_Barcelona', 'Circuit_Budapest', 'Circuit_Imola', 'Circuit_Jeddah', 'Circuit_Las Vegas', 'Circuit_Le Castellet', 'Circuit_Lusail', 'Circuit_Marina Bay', 'Circuit_Melbourne', 'Circuit_Mexico City', 'Circuit_Miami', 'Circuit_Monaco', 'Circuit_Montréal', 'Circuit_Monza', 'Circuit_Sakhir', 'Circuit_Shanghai', 'Circuit_Silverstone', 'Circuit_Spa-Francorchamps', 'Circuit_Spielberg', 'Circuit_Suzuka', 'Circuit_São Paulo', 'Circuit_Zandvoort', 'Driver_ALB', 'Driver_ALO', 'Driver_ANT', 'Driver_BEA', 'Driver_BOR', 'Driver_BOT', 'Driver_COL', 'Driver_DEV', 'Driver_DOO', 'Driver_GAS', 'Driver_HAD', 'Driver_HAM', 'Driver_HUL', 'Driver_LAT', 'Driver_LAW', 'Driver_LEC', 'Driver_MAG', 'Driver_MSC', 'Driver_NOR', 'Driver_OCO', 'Driver_PER', 'Driver_PIA', 'Driver_RIC', 'Driver_RUS', 'Driver_SAI', 'Driver_SAR', 'Driver_STR', 'Driver_TSU', 'Driver_VER', 'Driver_VET', 'Driver_ZHO']\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Encode Categorical Features\n",
    "categorical_features = ['Compound', 'FreshTyre', 'Rainfall', 'Circuit', 'Driver']\n",
    "categorical_features = [col for col in categorical_features if col in all_data.columns]\n",
    "all_data = pd.get_dummies(all_data, columns=categorical_features)\n",
    "print(all_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: ['LapTime', 'Sector1Time', 'Sector2Time', 'Sector3Time', 'SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST', 'TyreLife', 'Position', 'StintLapNumber', 'time_tire_stint', 'StartingTyreLife', 'Avg_AirTemp', 'Max_TrackTemp', 'Avg_Humidity', 'Max_Rainfall', 'Avg_WindSpeed']\n",
      "Categorical columns: ['LapNumber', 'Compound_HARD', 'Compound_INTERMEDIATE', 'Compound_MEDIUM', 'Compound_SOFT', 'Compound_WET', 'FreshTyre_False', 'FreshTyre_True', 'Circuit_Austin', 'Circuit_Baku', 'Circuit_Barcelona', 'Circuit_Budapest', 'Circuit_Imola', 'Circuit_Jeddah', 'Circuit_Las Vegas', 'Circuit_Le Castellet', 'Circuit_Lusail', 'Circuit_Marina Bay', 'Circuit_Melbourne', 'Circuit_Mexico City', 'Circuit_Miami', 'Circuit_Monaco', 'Circuit_Montréal', 'Circuit_Monza', 'Circuit_Sakhir', 'Circuit_Shanghai', 'Circuit_Silverstone', 'Circuit_Spa-Francorchamps', 'Circuit_Spielberg', 'Circuit_Suzuka', 'Circuit_São Paulo', 'Circuit_Zandvoort', 'Driver_ALB', 'Driver_ALO', 'Driver_ANT', 'Driver_BEA', 'Driver_BOR', 'Driver_BOT', 'Driver_COL', 'Driver_DEV', 'Driver_DOO', 'Driver_GAS', 'Driver_HAD', 'Driver_HAM', 'Driver_HUL', 'Driver_LAT', 'Driver_LAW', 'Driver_LEC', 'Driver_MAG', 'Driver_MSC', 'Driver_NOR', 'Driver_OCO', 'Driver_PER', 'Driver_PIA', 'Driver_RIC', 'Driver_RUS', 'Driver_SAI', 'Driver_SAR', 'Driver_STR', 'Driver_TSU', 'Driver_VER', 'Driver_VET', 'Driver_ZHO']\n"
     ]
    }
   ],
   "source": [
    "exclude_cols = ['Year', 'RoundNumber', 'Driver', 'Stint', 'LapNumber', 'Time', 'RemainingLaps', 'StintLength', 'TrackStatus']\n",
    "feature_cols = ['LapTime', 'Sector1Time', 'Sector2Time', 'Sector3Time', 'SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST',\n",
    "                'TyreLife', 'Position', 'StintLapNumber', 'time_tire_stint', 'StartingTyreLife', 'Avg_AirTemp', \n",
    "                'Max_TrackTemp', 'Avg_Humidity', 'Max_Rainfall', 'Avg_WindSpeed', 'LapNumber']\n",
    "feature_cols += [col for col in all_data.columns if col.startswith('Compound_') or \n",
    "                 col.startswith('FreshTyre_') or col.startswith('Rainfall_') or col.startswith('Circuit_') or \n",
    "                 col.startswith('Driver_')]\n",
    "feature_cols = [col for col in feature_cols if col in all_data.columns]\n",
    "\n",
    "numeric_cols = [col for col in feature_cols if not (col.startswith('Compound_') or \n",
    "                                                    col.startswith('FreshTyre_') or \n",
    "                                                    col.startswith('Rainfall_') or \n",
    "                                                    col.startswith('Circuit_') or \n",
    "                                                    col.startswith('Driver_') or\n",
    "                                                    col.startswith('LapNumber'))]\n",
    "categorical_cols = [col for col in feature_cols if col not in numeric_cols]\n",
    "numeric_indices = [feature_cols.index(col) for col in numeric_cols]\n",
    "\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, feature_cols, window_size=5):\n",
    "    sequences, targets = [], []\n",
    "    grouped = data.groupby(['Year', 'RoundNumber', 'driv', 'Stint'])\n",
    "    for _, group in grouped:\n",
    "        if len(group) >= window_size:\n",
    "            for i in range(len(group) - window_size + 1):\n",
    "                sequence = group.iloc[i:i + window_size][feature_cols].values\n",
    "                sequences.append(sequence)\n",
    "                target = group['RemainingLaps'].iloc[i + window_size - 1]\n",
    "                targets.append(target)\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "window_size = 2\n",
    "X, y = create_sequences(all_data, feature_cols, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = all_data[all_data['Year'].isin([2022, 2023])]\n",
    "val_data = all_data[all_data['Year'] == 2024]\n",
    "test_data = all_data[all_data['Year'] == 2025]\n",
    "\n",
    "window_size = 2\n",
    "X_train, y_train = create_sequences(train_data, feature_cols, window_size)\n",
    "X_val, y_val = create_sequences(val_data, feature_cols, window_size)\n",
    "X_test, y_test = create_sequences(test_data, feature_cols, window_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_numeric = X_train[:, :, numeric_indices]\n",
    "X_val_numeric = X_val[:, :, numeric_indices]\n",
    "X_test_numeric = X_test[:, :, numeric_indices]\n",
    "\n",
    "X_train_numeric_flat = X_train_numeric.reshape(-1, len(numeric_indices))\n",
    "X_val_numeric_flat = X_val_numeric.reshape(-1, len(numeric_indices))\n",
    "X_test_numeric_flat = X_test_numeric.reshape(-1, len(numeric_indices))\n",
    "\n",
    "scaler.fit(X_train_numeric_flat)\n",
    "\n",
    "X_train_numeric_scaled = scaler.transform(X_train_numeric_flat).reshape(X_train.shape[0], window_size, len(numeric_indices))\n",
    "X_val_numeric_scaled = scaler.transform(X_val_numeric_flat).reshape(X_val.shape[0], window_size, len(numeric_indices))\n",
    "X_test_numeric_scaled = scaler.transform(X_test_numeric_flat).reshape(X_test.shape[0], window_size, len(numeric_indices))\n",
    "\n",
    "X_train_scaled = np.copy(X_train)\n",
    "X_val_scaled = np.copy(X_val)\n",
    "X_test_scaled = np.copy(X_test)\n",
    "\n",
    "X_train_scaled[:, :, numeric_indices] = X_train_numeric_scaled\n",
    "X_val_scaled[:, :, numeric_indices] = X_val_numeric_scaled\n",
    "X_test_scaled[:, :, numeric_indices] = X_test_numeric_scaled\n",
    "\n",
    "X_train = X_train_scaled\n",
    "X_val = X_val_scaled\n",
    "X_test = X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sequences: (43275, 2, 81), Targets: (43275,)\n",
      "Validation sequences: (20319, 2, 81), Targets: (20319,)\n",
      "Test sequences: (10208, 2, 81), Targets: (10208,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training sequences: {X_train.shape}, Targets: {y_train.shape}\")\n",
    "print(f\"Validation sequences: {X_val.shape}, Targets: {y_val.shape}\")\n",
    "print(f\"Test sequences: {X_test.shape}, Targets: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train_data.csv with shape (43275, 163)\n",
      "Saved val_data.csv with shape (20319, 163)\n",
      "Saved test_data.csv with shape (10208, 163)\n"
     ]
    }
   ],
   "source": [
    "def save_sequences_to_csv(X, y, feature_cols, window_size, filename):\n",
    "    n_samples, n_timesteps, n_features = X.shape\n",
    "    columns = [f\"{col}_t{i+1}\" for i in range(n_timesteps) for col in feature_cols]\n",
    "    columns.append('RemainingLaps')\n",
    "    \n",
    "    X_flat = X.reshape(n_samples, -1)\n",
    "    data = np.hstack((X_flat, y.reshape(-1, 1)))\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved {filename} with shape {df.shape}\")\n",
    "\n",
    "save_sequences_to_csv(X_train, y_train, feature_cols, window_size, 'train_data.csv')\n",
    "save_sequences_to_csv(X_val, y_val, feature_cols, window_size, 'val_data.csv')\n",
    "save_sequences_to_csv(X_test, y_test, feature_cols, window_size, 'test_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs7641",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
